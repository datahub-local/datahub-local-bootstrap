---
k3s_cluster:
  children:
    server:
      hosts:
        k3s-server-0:
          ansible_host: 192.0.2.50

          # extra_volumes: # Mount extra volumes if needed
          #   some_volume_a:
          #     name: abc # Name of the device taken from /dev/abc.
          #     path: "/some-path" # Path to mount the volume.
          #     fstype: ext4 # Type of volume. By default: ext4.
          # required_directories: # Create required directories if needed
          #   - /var/lib/k3s
          # k3s_server_longhorn_enabled: true # Enable Longhorn in the server
    agent:
      hosts:
        k3s-agent-1:
          ansible_host: 192.0.2.51

          # extra_volumes: # Mount extra volumes if needed
          #   some_volume_a:
          #     id: abc # Id of the device taken from /dev/abc.
          #     path: "/some-path" # Path to mount the volume.
          #     fstype: ext4 # Type of volume. By default: ext4.
          # required_directories: # Create required directories if needed
          #   - /var/lib/k3s
          # k3s_gpu_nvidia_enabled: false # Enable GPU NVIDIA in the agent
          # k3s_agent_longhorn_enabled: true # Enable Longhorn in the agent
        k3s-agent-2:
          ansible_host: 192.0.2.52

          # extra_volumes: # Mount extra volumes if needed
          #   some_volume_a:
          #     name: abc # Name of the device taken from /dev/abc.
          #     path: "/some-path" # Path to mount the volume.
          #     fstype: ext4 # Type of volume. By default: ext4.
          # required_directories: # Create required directories if needed
          #   - /var/lib/k3s
          # k3s_gpu_nvidia_enabled: false # Enable GPU NVIDIA in the agent
          # k3s_agent_longhorn_enabled: true # Enable Longhorn in the agent
    agent_droid:
      hosts:
        k3s-agent_droid-1:
          ansible_host: 192.0.2.53
          ansible_user: u0_1234 # Example Android user

  # Required Vars
  vars:
    ansible_port: 22
    ansible_user: debian
    k3s_version: v1.29.2+k3s1
    token: "mytoken" # Use ansible vault if you want to keep it secret
    api_endpoint: "{{ groups['server'][0]] }}"
    extra_server_args: ""
    extra_agent_args: ""

    extra_packages: # Install extra packages
      - vim

    ###############################
    # Optional vars
    ###############################
    # os_upgrade: false # Upgrade the OS before installing K3s
    # k3s_context_name: k3s-ansible
    # api_port: 6443
    # k3s_location: /var/lib/rancher/k3s
    # k3s_server_no_schedule: true # No schedule pods by default in the server nodes
    # systemd_dir: /etc/systemd/system
    # extra_service_envs: [ 'ENV_VAR1=VALUE1', 'ENV_VAR2=VALUE2' ]
    # # Manifests or Airgap should be either full paths or relative to the playbook directory.
    # # List of locally available manifests to apply to the cluster, useful for PVCs or Traefik modifications.
    # extra_manifests: [ '/path/to/manifest1.yaml', '/path/to/manifest2.yaml' ]
    # airgap_dir: /tmp/k3s-airgap-images
    # user_kubectl: true # true by default kubectl is symlinked and configured for use by ansible_user. Set to false to only kubectl via root user.
    # server_config_yaml: # See https://docs.k3s.io/installation/configuration#configuration-file
    # etc_hosts_file: /etc/hosts # Sets the hosts file to use
    # wipe_data: false # Wipe the data

bootstrap:
  hosts:
    localhost:
      ansible_host: 127.0.0.1

  vars:
    ###############################
    # Bootstrap vars
    ###############################
    # k3s_context_name: k3s-ansible
    # ingress_hostname: "example.com" # hostname used in all the Ingress resources
    # enable_service_monitors: "false" # True if service monitors must be created. Must be false until an appropiate Prometheus is installed

    # security_enabled: false # false if we want to enable Traefik Oauth authentication.
    # # See https://oauth2-proxy.github.io/oauth2-proxy/configuration/providers/github for how to configure the OAuth provider with Github
    # security_github_client_id: some_client # Client ID
    # security_github_client_secret: some_secret # Client Secret
    # security_github_organizations: security_github_organizations: "my-organization,my-organization-with-teams:red-team|blue-team" # List of organizations
    # security_static_users: | # htpasswd entries for auth with DEX Token (https://dexidp.io/docs/connectors/local/).
    #   - email: "admin@example.com"
    #     # bcrypt hash of the string "password": $(echo password | htpasswd -BinC 10 admin | cut -d: -f2)
    #     hash: "$2a$10$2b2cU8CPhOTaGrs1HRQuAueS7JTT5ZHsHSzYiFPm1leZck7Mc8T4W"
    #     username: "admin"
    #     userID: "08a8684b-db88-4b73-90a9-3cd1661f5466"

    #  - "user1:$2y$05$/sZYJOk8.3Etg4V6fV7puuXfCJLmV5Q7u3xvKpjBSJUka.t2YtmmG" # admin:Adm1n1str$t0r
    # security_dex_extra_clients: | # List extra clients to create in DEX.
    #   - id: some-app
    #     name: "Some App"
    #     redirectURIs:
    #       - "https://some-app.{{ingress_hostname}}/api/dex/callback"
    #   secret: "{{ some_secret_var }}"

    # # See https://cert-manager.io/docs/configuration/acme/ for how to configure cert-manager
    # cert_manager_cluster_issuer_spec:
    #   selfSigned: {}
    # cert_manager_cluster_issuer_secret_name: # Name of the secret where the issuer will get the credentials
    # cert_manager_cluster_issuer_secret_data: # Data of the secret that the issuer will get the credentials
    # # Example using Cloudfare:
    # cert_manager_cluster_issuer_spec:
    #   acme:
    #     email: "email@example.com"
    #     server: "https://acme-staging-v02.api.letsencrypt.org/directory"

    #     privateKeySecretRef:
    #       name: default-cluster-issuer
    #     solvers:
    #       - dns01:
    #           cloudflare:
    #             apiTokenSecretRef:
    #               name: cert-manager-token
    #               key: api-token
    # cert_manager_cluster_issuer_secret_name: cert-manager-token # Name of the secret where the issuer will get the credentials
    # cert_manager_cluster_issuer_secret_data: # Data of the secret that the issuer will get the credentials
    #   api-token: "some-token"

    # # See https://github.com/kubernetes-sigs/external-dns/blob/master/charts/external-dns/README.md#provider for how to configure external-dns
    # external_dns_secret_name: # Name of the secret where the  will get the credentials
    # external_dns_secret_data: # Data of the secret that the issuer will get the credentials
    # external_dns_helm_values: # Helm values to configure it. See https://github.com/kubernetes-sigs/external-dns/blob/master/charts/external-dns/values.yaml

    # longhorn_enabled: true # false if we want to disable Longhorn installation.
    # longhorn_enabled_only_agent: false # true if we want to enable Longhorn only in agents.
    # longhorn_replica_count: 2 # num of replicas that Longhorn will use. More replicas, more space required
    # longhorn_storage_minimal_available_percentage: 25 # Minimal available percentage of storage that Longhorn will use. Default is 25%.
    # longhorn_storage_reserved_percentage_for_default_disk: 30 # Minimal available percentage of storage that Longhorn will use. Default is 30%.
    # longhorn_data_dir: /var/lib/longhorn/ # Default path for storing data on a host.

    # nfs_external_provisioner_enabled: true # false if we want to disable NFS External Provisioner installation.
    # nfs_external_provisioner_server: some_server # NFS server IP or hostname
    # nfs_external_provisioner_path: /some_path # NFS server path

    # argocd_enabled: true # false if we want to disable ArgoCD installation.
    # argocd_namespaces: # namespaces where argo-cd will look for apps
    #   - default
    #   - automation
    # argocd_credential_templates: # Helm values to configure it. See https://argo-cd.readthedocs.io/en/stable/operator-manual/argocd-repo-creds-yaml/ and https://github.com/argoproj/argo-helm/blob/main/charts/argo-cd/values.yaml
    #   ssh-creds:
    #     url: git@github.com:argoproj-labs
    #     sshPrivateKey: |
    #       -----BEGIN OPENSSH PRIVATE KEY-----
    #       ...
    #       -----END OPENSSH PRIVATE KEY-----

    # k8s_device_plugin_enabled: true # false if we want to disable NVIDIA device plugin installation.
